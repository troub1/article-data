{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "infile = '' # input file name (final data ready for OA retrieval and XML creation)\n",
    "#data = pd.read_excel(infile, sheet_name='Sheet4') # change/remove sheet name if necessary\n",
    "#data = pd.read_csv(infile, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split names and return a list of individual authors, so they can be specified in the XML to properly be entered as individual creators\n",
    "def split_names(names):\n",
    "    names_list = names.split(', ')\n",
    "    split_list = []\n",
    "    for name in names_list:\n",
    "        split_list.append(name.replace(' ', ', ', 1))\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove certain characters from item text to prevent errors in DSpace batch import. An initial list is here:\n",
    "# https://www.tdl.org/wp-content/uploads/2009/04/DSpaceBatchImportFormat.pdf\n",
    "# and may receive more from Felicity.\n",
    "# So we create a dictionary to map the special character to the escaped version (or other change to problematic characters)\n",
    "# then create a translation table with str.maketrans. This will then be used in the 'build_xml' function to translate each field\n",
    "# as it is inserted into the XML.\n",
    "trans_dict = {\n",
    "    '&': '&amp;',\n",
    "    '\\'': '&apos;',\n",
    "    '\\\"': '&quot;',\n",
    "    '<': '&lt;',\n",
    "    '>': '&gt;',\n",
    "    '%': ' percent',\n",
    "    '°': ' degrees',\n",
    "    '≥': '[greater than or equal to]',\n",
    "    '≤': '[less than or equal to]',\n",
    "    '©': '[copyright]',\n",
    "    '™': '[trademark]',\n",
    "    '—': '--',\n",
    "    'α': '[alpha]',\n",
    "    'β': '[beta]',\n",
    "    'μ': '&#181;',\n",
    "    '×': 'x',\n",
    "    '±': '[plus or minus]',\n",
    "    '~': '&#126;',\n",
    "    '♭': '[flat]',\n",
    "    '’': \"'\"\n",
    "}\n",
    "\n",
    "trans_table = str.maketrans(trans_dict)\n",
    "\n",
    "# based on https://www.semicolonworld.com/question/56290/how-do-convert-a-pandas-dataframe-to-xml\n",
    "def build_xml_block(row):\n",
    "    xml = ['<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<dublin_core>']\n",
    "    citation = {}\n",
    "#    print(row)\n",
    "    for field in row.index:\n",
    "        if field in [\"Title\"]:\n",
    "            xml.append('    <dcvalue element=\"title\" qualifier=\"none\" language=\"eng\">{0}</dcvalue>'.format(row[field].translate(trans_table)))\n",
    "            citation['title'] = row[field].translate(trans_table)\n",
    "        elif field in [\"Authors\"]:\n",
    "            xml.append('    <dcvalue element=\"contributor\" qualifier=\"author\" language=\"eng\">{0}</dcvalue>'.format('||'.join(split_names(row[field])).translate(trans_table)))\n",
    "            citation['authors'] = ', '.join(split_names(row[field])).translate(trans_table)\n",
    "        elif field == \"corr department\":\n",
    "            xml.append('    <dcvalue element=\"contributor\" qualifier=\"deptlab\" language=\"eng\">{0}</dcvalue>'.format(row[field].translate(trans_table)))            \n",
    "        elif field == \"Abstract\":\n",
    "            xml.append('    <dcvalue element=\"description\" qualifier=\"abstract\" language=\"eng\">{0}</dcvalue>'.format(row[field].translate(trans_table)))\n",
    "        elif field == \"DOI\":\n",
    "            xml.append('    <dcvalue element=\"identifier\" qualifier=\"uri\" language=\"eng\">https://dx.doi.org/{0}</dcvalue>'.format(row[field]))\n",
    "            xml.append('    <dcvalue element=\"identifier\" qualifier=\"none\" language=\"eng\">{0}</dcvalue>'.format(row[field]))\n",
    "            citation['doi'] = row[field].translate(trans_table)\n",
    "        elif field == \"Source title\":\n",
    "            xml.append('    <dcvalue element=\"source\" qualifier=\"none\" language=\"eng\">{0}</dcvalue>'.format(row[field].translate(trans_table)))\n",
    "            citation['source'] = row[field].translate(trans_table)\n",
    "        elif field == \"Document Type\":\n",
    "            xml.append('    <dcvalue element=\"type\" qualifier=\"none\" language=\"eng\">{0}</dcvalue>'.format(row[field]))\n",
    "        #elif field == \"pubdate\":\n",
    "        elif field == \"Year\":            \n",
    "            xml.append('    <dcvalue element=\"date\" qualifier=\"issued\" language=\"eng\">{0}</dcvalue>'.format(row[field]))\n",
    "            citation['year'] = row[field]\n",
    "        elif field == \"Publisher\":\n",
    "            xml.append('    <dcvalue element=\"publisher\" qualifier=\"none\" language=\"eng\">{0}</dcvalue>'.format(row[field].translate(trans_table)))\n",
    "        elif field == \"best_oa_license\":\n",
    "            xml.append('    <dcvalue element=\"rights\" qualifier=\"license\" language=\"eng\">{0}</dcvalue>'.format(row[field]))\n",
    "            licenses = {\n",
    "                'cc-by': 'https://creativecommons.org/licenses/by/4.0',\n",
    "                'cc-by-nc': 'https://creativecommons.org/licenses/by-nc/4.0',\n",
    "                'cc-by-nc-nd': 'https://creativecommons.org/licenses/by-nc-nd/4.0',\n",
    "                'cc0': 'https://creativecommons.org/publicdomain/zero/1.0/',\n",
    "                'cc-by-nc-sa': 'https://creativecommons.org/licenses/by-nc-sa/4.0'\n",
    "            }\n",
    "            xml.append('    <dcvalue element=\"rights\" qualifier=\"license\" language=\"eng\">{0}</dcvalue>'.format(licenses.get(row[field]), ''))\n",
    "        elif field == \"Author Keywords\":\n",
    "            if not pd.isnull(row[field]):\n",
    "                xml.append('    <dcvalue element=\"subject\" qualifier=\"none\" language=\"eng\">{0}</dcvalue>'.format(row[field].translate(trans_table)))\n",
    "        elif field == \"Volume\":\n",
    "            if not pd.isnull(row[field]):\n",
    "                citation['volume'] = row[field]\n",
    "        elif field == \"Issue\":\n",
    "            if not pd.isnull(row[field]):\n",
    "                citation['issue'] = '('+str(row[field])+')'\n",
    "            ## For now, replacing null/NaN issue with blank, eventually probably want to build citation by appending values if they exist,\n",
    "            ## rather than assuming they exist and appending empty string if they don't...\n",
    "            else:\n",
    "                citation['issue'] = ''\n",
    "    \n",
    "    citation_string = '{0}. ({1}). {2}. {3}, {4}{5}. {6}'.format(citation['authors'], citation['year'], citation['title'], citation['source'], \n",
    "                                                                                 citation['volume'], citation['issue'], citation['doi']).translate(trans_table)\n",
    "\n",
    "    xml.append('    <dcvalue element=\"source\" qualifier=\"none\" language=\"eng\">{0}</dcvalue>'.format(citation_string))\n",
    "    xml.append('</dublin_core>')\n",
    "    return '\\n'.join(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n'.join(data[35:38].apply(build_xml_block, axis=1))) #take a look/print/output XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['best_oa_url_for_pdf'][0] #just looking at this field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://likegeeks.com/downloading-files-using-python/\n",
    "import requests, os\n",
    "# https://stackoverflow.com/questions/34446172/open-url-in-new-tab-from-ipython-notebook-jupyter-cell\n",
    "import webbrowser\n",
    "\n",
    "def get_articles(start, stop):\n",
    "    manual_download = []\n",
    "    myfile = 0\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if index < start:\n",
    "            continue\n",
    "        elif index >=stop:\n",
    "            break\n",
    "\n",
    "        unsanitized_local_path = os.path.join('pdfs', row['corr surname']+' - '+row['Title'][:20])\n",
    "        local_path = \"\".join(i for i in unsanitized_local_path.rstrip() if i not in r':*?\"<>|/')\n",
    "\n",
    "        print(index, row['corr surname']+' - '+row['Title'])            \n",
    "\n",
    "        if os.path.exists(os.path.join(local_path, row['corr surname']+'.pdf')):\n",
    "            print('File already downloaded...skipping\\n')\n",
    "            continue\n",
    "        \n",
    "        # OUP seems to close connection immediately to non-browser requests? Check both for no direct pdf link AND that it's not\n",
    "        # an OUP link. If either of those, must download manually.\n",
    "        if not pd.isnull(row['best_oa_url_for_pdf']) and not 'academic.oup.com' in str(row['best_oa_url_for_pdf']):\n",
    "            print(row['best_oa_url_for_pdf'], '\\n')\n",
    "            \n",
    "            if not os.path.exists(local_path):\n",
    "                os.makedirs(local_path)            \n",
    "            \n",
    "            try:\n",
    "                myfile = requests.get(row['best_oa_url_for_pdf'])\n",
    "                myfile.raise_for_status\n",
    "                open(os.path.join(local_path, row['corr surname']+'.pdf'), 'wb').write(myfile.content)\n",
    "                print('Response code: ', myfile.status_code)\n",
    "                print('Complete: ', len(myfile.content), 'bytes\\n')\n",
    "            except requests.exceptions.HTTPError as errh:\n",
    "                print (\"HTTP Error:\",errh, '\\n')\n",
    "                open(os.path.join(local_path, row['corr surname']+'.pdf'), 'wb')\n",
    "            except requests.exceptions.ConnectionError as errc:\n",
    "                print (\"Error Connecting:\",errc, '\\n')\n",
    "                open(os.path.join(local_path, row['corr surname']+'.pdf'), 'wb')\n",
    "            except requests.exceptions.Timeout as errt:\n",
    "                print (\"Timeout Error:\",errt, '\\n')\n",
    "                open(os.path.join(local_path, row['corr surname']+'.pdf'), 'wb')\n",
    "            except requests.exceptions.RequestException as err:\n",
    "                print (\"Error:\",err, '\\n')\n",
    "                open(os.path.join(local_path, row['corr surname']+'.pdf'), 'wb')\n",
    "                print(err.response.text)\n",
    "\n",
    "            open(os.path.join(local_path, 'dublin_core.xml'), 'w', encoding='UTF-8').write(build_xml_block(row))\n",
    "            open(os.path.join(local_path, 'contents'), 'w').write(row['corr surname']+'.pdf')\n",
    "        else:\n",
    "            if not os.path.exists(local_path):\n",
    "                os.makedirs(local_path)\n",
    "            print('NO DIRECT URL')\n",
    "            print(row['best_oa_url'])\n",
    "            manual_download.append(row)\n",
    "            #webbrowser.open(row['best_oa_url'])\n",
    "            open(os.path.join(local_path, row['corr surname']+'.pdf'), 'wb')\n",
    "            open(os.path.join(local_path, 'dublin_core.xml'), 'w', encoding='UTF-8').write(build_xml_block(row))\n",
    "            open(os.path.join(local_path, 'contents'), 'w', encoding='UTF-8').write(row['corr surname']+'.pdf')\n",
    "            print('Browser tab opened, overwrite empty pdf: ', os.path.join(local_path, row['corr surname']+'.pdf'),'\\n')\n",
    "\n",
    "    #    print('\\n\\n'.join(data[10:20].apply(func, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_articles(0, 50) #get first 50 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[-1] #take a look at last entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Number', 'Authors', 'Author(s) ID', 'Title', 'Year', 'Source title',\n",
       "       'Volume', 'Issue', 'Art. No.', 'Page start', 'Page end', 'Page count',\n",
       "       'Cited by', 'DOI', 'Link', 'Affiliations', 'Authors with affiliations',\n",
       "       'Abstract', 'Author Keywords', 'Funding Details',\n",
       "       'Correspondence Address', 'Publisher', 'ISSN', 'ISBN', 'CODEN',\n",
       "       'Document Type', 'Publication Stage', 'Access Type', 'Source', 'EID',\n",
       "       'corr email', 'corr given name', 'corr surname', 'corr department',\n",
       "       'best_oa_license', 'best_oa_url', 'best_oa_url_for_pdf',\n",
       "       'best_oa_version', 'best_oa_evidence', 'librarian_name',\n",
       "       'librarian_email'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys() #check keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
