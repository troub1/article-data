{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: 01_get_article_data\n",
    "# Author: Steven Pryor, github.com/troub1\n",
    "# Retrieves and/or processes article data from .csv file\n",
    "    #currently (Feb 2021), this has been done by searching the Scopus web interface and downloading a CSV. The .csv is then imported here as a dataframe for processing\n",
    "# Retrieves and combines additional data from Unpaywall\n",
    "\n",
    "# 1. Download raw data from Scopus (and/or WoS, though check field names)\n",
    "# 2. Clean up with OpenRefine\n",
    "#    a. Publisher names\n",
    "#    b. \n",
    "#    c. \n",
    "# 3. Read cleaned file, get additional OA data from Unpaywall for each DOI\n",
    "# 4. Get contact info, names, and department for each MU Corresponding Author (store a file/database of already-collected authors to check first before LDAP lookup? This could also help w/ future process for non-corresponding authors)\n",
    "# 5. Match librarians to each author by department\n",
    "# 6. Gold OA articles\n",
    "#    a. Send emails to authors and librarians notifying of MOspace collection of OA articles\n",
    "#    b. Retrieve articles\n",
    "#    c. Create metadata and batch ingest files\n",
    "# 7. CREATE PROCESS HERE FOR Green-Available (also harvest? Could be issues with other repos' cover pages, copyright statements, licenses...other things?)\n",
    "# 8. CREATE PROCESS HERE FOR Green-Potential\n",
    "#        - Need to figure out how to best identify the authors\n",
    "# 9. CREATE PROCESS FOR UPDATE\n",
    "#      - Check for new/updated Unpaywall data?\n",
    "#      - Check for new articles or new/updated Scopus data\n",
    "#      - Add and combine with WoS or other data sources to expand coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import pandas as pd\n",
    "import requests, time\n",
    "\n",
    "test_doi = \"10.1080/01930826.2014.893110\"\n",
    "api_unpaywall = \"https://api.unpaywall.org/v2/\"\n",
    "params_unpaywall = {'email':''} #enter your email address here\n",
    "unpaywall_results = []\n",
    "\n",
    "infile = '' # input: filename for raw Scopus data (or whatever data file with DOIs to be augmented with Unpaywall data)\n",
    "outfile = '' # output: filename for Scopus data with added Unpaywall columns\n",
    "\n",
    "#---------------\n",
    "#Choose one of the functions below based on whether your input file is .csv or .xls\n",
    "#scopus_Data = pd.read_excel(infile)\n",
    "#scopus_Data = pd.read_csv(infile, encoding='ANSI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This function loops through the DOI list and queries unpaywall for any known OA locations for each DOI. The result is a json object identifying whether each document has an OA location, the best OA location (if any)\n",
    "##URLs to pdfs, etc. The json results will be saved into a list (unpaywall_results) as well as written to a file (50,000+ API calls takes several hours to complete; save it when you're done! Could multithread, bah!)\n",
    "\n",
    "def get_unpaywall(doi_list):\n",
    "    for doi in doi_list:\n",
    "        if not pd.isnull(doi):\n",
    "            try:\n",
    "                result = requests.get(api_unpaywall + doi, params=params_unpaywall)\n",
    "            except (requests.HTTPError, requests.RequestException) as e:\n",
    "                print(\"Error: \" + e)\n",
    "            unpaywall_results.append(result.json())\n",
    "        else:\n",
    "            unpaywall_results.append({})\n",
    "        \n",
    "        print(\".\", end=\"\")\n",
    "        if not len(unpaywall_results)%5000:\n",
    "            print(\"\\n(+5K) Still working...\")\n",
    "    print(\"Done\\n\")\n",
    "    \n",
    "    ##Now read in the unpaywall results to a pandas DataFrame so we can play around with it\n",
    "    unpaywall_Data = pd.read_json(path_or_buf=json.JSONEncoder().encode(unpaywall_results), orient=\"records\")\n",
    "    \n",
    "    print(\"COMPARISON:\\n\")\n",
    "    print(unpaywall_Data['title'][:-9], '\\n===================\\n')\n",
    "    print(scopus_Data['Title'][:-9])\n",
    "    \n",
    "    ##The unpaywall json result contains lists as elements, ie the best_oa_location 'column' of the DataFrame contains a list of the location URL, license, etc. We need to \"flatten\" or expand this list out, so we'll\n",
    "    ##extract it as a series, rename the columns with a prefix indicating the original location, and then concatenate the columns onto the DataFrame/table. This lets us see and reference the list nested inside\n",
    "    ##the best_oa_location column and perform operations/counts/etc. on it\n",
    "    best_oa = unpaywall_Data['best_oa_location'].apply(pd.Series)\n",
    "    best_oa = best_oa.rename(columns = lambda x : 'best_oa_' + str(x))\n",
    "    ##Also expand out the list of authors\n",
    "    #authors = df['z_authors'].apply(pandas.Series)\n",
    "    #authors = authors.rename(columns = lambda x : 'authors' + str(x))\n",
    "    unpaywall_Data_expanded = pd.concat([unpaywall_Data[:], best_oa[:]], axis=1)\n",
    "    \n",
    "    return unpaywall_Data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaywall_df = get_unpaywall(scopus_Data['DOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now combine the Unpaywall data we want with the rest of the data from Scopus by adding columns:\n",
    "scopus_Data['best_oa_license'] = unpaywall_df['best_oa_license']\n",
    "scopus_Data['pubdate'] = unpaywall_df['published_date']\n",
    "scopus_Data['oa_status'] = unpaywall_df['oa_status']\n",
    "scopus_Data['best_oa_evidence'] = unpaywall_df['best_oa_evidence']\n",
    "scopus_Data['best_oa_url_for_pdf'] = unpaywall_df['best_oa_url_for_pdf']\n",
    "scopus_Data['best_oa_url'] = unpaywall_df['best_oa_url']\n",
    "scopus_Data['best_oa_version'] = unpaywall_df['best_oa_version']\n",
    "scopus_Data['journal_is_oa'] = unpaywall_df['journal_is_oa']\n",
    "scopus_Data['is_oa'] = unpaywall_df['is_oa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"green open access\" potential OA column\n",
    "# Use list of defined preferred publisher names (for OpenRefine step)\n",
    "# Build list of Publishers with confirmed Green OA policies of some kind\n",
    "# These are matches from high-number publishers in one of our data sets; if your faculty publish different places you might want to check different publishers and add some here, too\n",
    "green_oa_pubs = ['Elsevier Ltd', 'Blackwell Publishing Ltd', 'John Wiley and Sons Inc.', 'Springer', 'Nature Publishing Group', 'Springer International Publishing', 'Informa UK Limited', 'SAGE Publications Inc.', \n",
    "                 'American Chemical Society', 'Elsevier', 'Public Library of Science (PLoS)', 'Frontiers Media SA', 'Oxford University Press', 'Ovid Technologies (Wolters Kluwer Health)', \n",
    "                 'IEEE', 'Institute of Electrical and Electronics Engineers Inc.', 'American Physical Society (APS)', 'Taylor and Francis', 'Routledge' ]\n",
    "oa_potential = []\n",
    "\n",
    "for index, row in scopus_Data.iterrows():\n",
    "    # For \"potential OA\" count, count whether the publisher has a green OA policy *or* it's already available (we want to add up the total of already-OA and could-be-OA)\n",
    "    if( (row['Publisher'] in green_oa_pubs) or row['is_oa'] or row['journal_is_oa'] ):\n",
    "       oa_potential.append('1')\n",
    "    else:\n",
    "       oa_potential.append('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_Data['potential_oa'] = oa_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save our work!\n",
    "scopus_Data.to_csv(outfile, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "#END data collection code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
